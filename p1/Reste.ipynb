{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIFFERENT APPROACH: SCORE DIFFERENCE IN 50/50 SPLIT\n",
    "Does that solve the range problems caused by gamma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_BOOTSTRAP = 100\n",
    "gamma_range = np.linspace(0.1, 2, 40)\n",
    "\n",
    "score_diff = np.zeros((len(df), N_BOOTSTRAP, len(gamma_range)))\n",
    "\n",
    "hardmin_diff = np.zeros((len(df), N_BOOTSTRAP))\n",
    "\n",
    "# NECESSARY TO USE ALL INSTANCES\n",
    "def clean_distances(z):\n",
    "    if z[0] == 0:\n",
    "        return z[1:]\n",
    "    else:\n",
    "        return z[0:-1]\n",
    "\n",
    "\n",
    "for i in range(0, N_BOOTSTRAP):\n",
    "\n",
    "    # 50/50 split\n",
    "    sample = df.sample(frac=0.5)\n",
    "    rest = df.drop(sample.index)\n",
    "\n",
    "    # USE ALL INSTANCES\n",
    "    nbrs = NearestNeighbors(n_neighbors=len(sample), algorithm=\"ball_tree\").fit(sample)\n",
    "    distances1, _ = nbrs.kneighbors(df)\n",
    "    distances1 = np.apply_along_axis(clean_distances, 1, distances1)\n",
    "    distances1 = np.square(distances1)\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=len(rest), algorithm=\"ball_tree\").fit(rest)\n",
    "    distances2, _ = nbrs.kneighbors(df)\n",
    "    distances2 = np.apply_along_axis(clean_distances, 1, distances2)\n",
    "    distances2 = np.square(distances2)\n",
    "\n",
    "    for j, gamma in enumerate(gamma_range):\n",
    "        sm1 = np.apply_along_axis(softmin_og, 1, distances1, gamma)\n",
    "        sm2 = np.apply_along_axis(softmin_og, 1, distances2, gamma)\n",
    "\n",
    "        score_diff[:, i, j] = sm2 - sm1\n",
    "\n",
    "    # hardmin\n",
    "    hardmin1 = distances1[:, 1]\n",
    "    hardmin2 = distances2[:, 1]\n",
    "\n",
    "    hardmin_diff[:, i] = hardmin2 - hardmin1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardmin has low bias but high variance (not so robust)\n",
    "# TODO interpretation of that value corect?\n",
    "np.mean(np.var(hardmin_diff, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardmin score # TODO interpretation of that value?\n",
    "np.var(np.mean(hardmin_diff, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = np.var(score_diff, axis=1)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    plt.plot(gamma_range, spread[i], linewidth=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustness (how much to the scores vary over the bootstrap samples?)\n",
    "# robustness increases with lower gamma (but high bias)\n",
    "sns.scatterplot(x = gamma_range, y=np.mean(spread, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_diff = np.mean(score_diff, axis=1)\n",
    "\n",
    "for i in range(len(scores)):\n",
    "    plt.plot(gamma_range, avg_score_diff[i], linewidth=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure discrimination \n",
    "# how good can we distinguish between the scores?\n",
    "# higher variance is better here to identify the outliers\n",
    "sns.scatterplot(x = gamma_range, y=np.var(avg_score_diff, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = np.mean(spread, axis=0), y=np.var(avg_score_diff, axis=0), hue=gamma_range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm=\"ball_tree\").fit(df)\n",
    "distances, indices = nbrs.kneighbors(df)\n",
    "df_overview[\"outlier_score_min\"] = np.square(distances[:, 1])\n",
    "df_overview.sort_values(by=\"outlier_score_min\", ascending=False).head(10)\n",
    "print(distances.shape)\n",
    "# distances: Zeile = sample, Spalte 1 = kürzeste Distanz\n",
    "# Spalte 0 = alles 0\n",
    "print(indices.shape)\n",
    "# indices: erste Spalte 0-440; zweite Spalte: index zur kürzesten Distanz\n",
    "print(distances[0, 1], indices[0])\n",
    "# quick double check\n",
    "np.linalg.norm(df.iloc[0, :] - df.iloc[59, :])\n",
    "print(np.var(df_overview['outlier_score_min']))\n",
    "display(df_overview[[\"outlier_score_min\"]].describe())\n",
    "sns.boxplot(df_overview[\"outlier_score_min\"])\n",
    "plt.show()\n",
    "sns.histplot(df_overview[\"outlier_score_min\"])\n",
    "# want it to be centered/dense!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# score_bias_eval function before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare hardmin with hardmin-bootstrap appraoch by statistics as well as artificial outlier classification\n",
    "\n",
    "# def score_bias_eval(score, overview_data=df_overview, outlier_frac=OUTLIERS_FRAC):\n",
    "#     n_outliers = math.ceil(len(df_overview) * outlier_frac)\n",
    "#     spr = spearmanr(overview_data[score], df_overview[\"hardmin_bootstrap_score\"])\n",
    "#     hardmin_bootstrap_ranking = df_overview.sort_values(by=\"hardmin_bootstrap_score\", ascending=False).index\n",
    "#     hardmin_outliers = hardmin_bootstrap_ranking[:n_outliers]\n",
    "#     score_outlier_ranking = df_overview.sort_values(by=score, ascending=False).index\n",
    "#     score_outliers = score_outlier_ranking[:n_outliers]\n",
    "\n",
    "#     accuracy = len(set(hardmin_outliers).intersection(score_outliers)) / n_outliers\n",
    "#     return spr, accuracy\n",
    "\n",
    "# spr, acc = score_bias_eval(overview_data=df_overview, score=\"hardmin_score\")\n",
    "\n",
    "# print(f\"Bootstrap Accuracy: {acc:.2}% \\nSpearman results: {spr}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
